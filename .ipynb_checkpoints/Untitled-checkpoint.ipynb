{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "\n",
    "\n",
    "def parse(file_name: str):\n",
    "    \"\"\"\n",
    "    Convert input CSV data to a tuple of transaction list and dictionary of transaction items:\n",
    "\n",
    "    @param file_name: location of CSV data file\n",
    "    @type file_name: str\n",
    "    @return: transaction list: item words are converted to sequential index\n",
    "             transaction items: a dictionary mapping item word with its index\n",
    "    @rtype: Tuple[List[Set[int]], dict]\n",
    "    \"\"\"\n",
    "\n",
    "    # read csv file with pandas\n",
    "    data = pd.read_csv(file_name)\n",
    "\n",
    "    # Variable transaction_list - to store transaction\n",
    "    transaction_list = []\n",
    "\n",
    "    # Use a dict to store items from the given transactions\n",
    "    items_dict = {}\n",
    "\n",
    "    # index_count - sequential index of each item\n",
    "    index_count = 0\n",
    "\n",
    "    # total number of transactions of the given data\n",
    "    total_transaction_number = data.shape[0]\n",
    "\n",
    "    # maximum number of items per transaction (max number of columns) of the given data\n",
    "    max_items_per_tranx = data.shape[1]\n",
    "\n",
    "    for i in range(total_transaction_number):\n",
    "\n",
    "        # items_each_trx to store items in each transaction\n",
    "        items_each_trx = []\n",
    "\n",
    "        for j in range(max_items_per_tranx):\n",
    "\n",
    "            # get item j (position) of transaction i\n",
    "            item = data.iloc[i, j]\n",
    "            # if item is NaN or Null -> skip the loop\n",
    "            if str(item) == \"nan\":\n",
    "                continue\n",
    "            else:\n",
    "                # if the item is in items_dict, to add its index to transaction_list\n",
    "                if item.lower().strip() in items_dict:\n",
    "                    items_each_trx.append(items_dict[item.lower().strip()])\n",
    "\n",
    "                # if the item is NOT in items_dict, to compute its index, add to items_dict and\n",
    "                # add its index to transaction_list\n",
    "                else:\n",
    "                    items_dict[item.lower().strip()] = index_count\n",
    "                    items_each_trx.append(index_count)\n",
    "                    index_count += 1\n",
    "        transaction_list.append(items_each_trx)\n",
    "\n",
    "    return transaction_list, items_dict\n",
    "\n",
    "\n",
    "def get_candidates(transaction_list):\n",
    "    \"\"\"\n",
    "    Generate size-one-candidates (one-item sets) from the list of transactions\n",
    "    @param transaction_list: list of transactions with transaction items being coded by their sequential indexes\n",
    "    @type transaction_list: List[Set[int]]\n",
    "    @return: list of sets of size-one-candidate (one-item sets)\n",
    "    @rtype: List[Set(frozen)]\n",
    "    \"\"\"\n",
    "\n",
    "    # size_one_candidates: a list to store size-one candidates (one-item sets)    \n",
    "    size_one_candidates = []\n",
    "    # loop through each transaction to create  item sets of size-one (one-item sets)\n",
    "    for transaction in transaction_list:\n",
    "        for i in transaction:\n",
    "            i = frozenset([i])\n",
    "            if i not in size_one_candidates:\n",
    "                size_one_candidates.append(i)\n",
    "    return size_one_candidates\n",
    "\n",
    "\n",
    "def generate_candidate_k(freq_item: list, k: int) -> list:\n",
    "    \"\"\"\n",
    "    Generate list of  of size-(k+2) candidates from the  frequent item list (freq_item)\n",
    "\n",
    "    @param freq_item: List of qualified item sets (item sets with support >= min_support\n",
    "    @type freq_item:  List[]\n",
    "    @param k: k common items in two (k+1) itemset\n",
    "    @type k: int\n",
    "    @return: List of frequece itemset, size = k + 2\n",
    "    @rtype: List[frozen]\n",
    "    \"\"\"\n",
    "    size_k_candidates = []\n",
    "\n",
    "    # to generate candidates of size two (2-item sets)\n",
    "\n",
    "    if k == 0:\n",
    "        # if k = 0, size of itemset = 1 => size of common items = 0\n",
    "        for f1, f2 in combinations(freq_item, 2):\n",
    "            item = f1 | f2  # union of two sets\n",
    "            size_k_candidates.append(item)\n",
    "\n",
    "    # k > 0\n",
    "    else:\n",
    "        for f1, f2 in combinations(freq_item, 2):\n",
    "            # if the two (k+1)-item sets both has k common items\n",
    "            # then they will be combined to be the (k+2)-item candidate\n",
    "            # k >= 1, gen list common items in two itemset size (k+1)\n",
    "            intersection = f1 & f2\n",
    "            # if size of common items = k\n",
    "            if len(intersection) == k:\n",
    "                item = f1 | f2 # union of two sets, expected size-itemset = k + 2\n",
    "                if item not in size_k_candidates:\n",
    "                    size_k_candidates.append(item)\n",
    "\n",
    "    return size_k_candidates\n",
    "\n",
    "\n",
    "def create_freq_item(transaction_list, size_k_candidates, min_support):\n",
    "    \"\"\"\n",
    "    find candidates whose support >= min_support\n",
    "    @param transaction_list: list of transactions with transaction items being coded by their sequential indexes\n",
    "    @type transaction_list: List[Set[int]]\n",
    "    @param size_k_candidates: size-k itemset\n",
    "    @type size_k_candidates: List\n",
    "    @param min_support: The minimum fraction of transactions an itemets needs to occur in to be deemed frequent\n",
    "    @type min_support: float\n",
    "    @return:\n",
    "        freq_item: frequence itemset have support >= min_support\n",
    "        item_support: itemset with support index               \n",
    "    @rtype:\n",
    "        freq_item: List[frozen]\n",
    "        item_support: Dict, item: support, support is float, between 0 and 1\n",
    "    \"\"\"\n",
    "    # loop through the transaction and compute the count for each candidate (item)\n",
    "    item_count = {}\n",
    "\n",
    "    # check in each transaction\n",
    "    for transaction in transaction_list:\n",
    "\n",
    "        # to see if the items of each size-k candidate is part (subset) of the transaction\n",
    "        # if the candidate is the subset add to item_count dictionary together with its count\n",
    "        for candidate in size_k_candidates:\n",
    "            if candidate.issubset(transaction):\n",
    "                if candidate not in item_count:\n",
    "                    item_count[candidate] = 1\n",
    "                else:\n",
    "                    item_count[candidate] += 1\n",
    "\n",
    "    # total number of transactions\n",
    "    n_row = transaction_list.shape[0]\n",
    "\n",
    "    # freq_item indicates the frequency of occurence of each item set. To store the frequent item sets\n",
    "    freq_item = []\n",
    "\n",
    "    # if the support of an item is greater than the min_support, then it is considered as frequent\n",
    "    # compute support of each item set , if >= min_support -> append that item set to freq_item\n",
    "    item_support = {}\n",
    "\n",
    "    for item in item_count:\n",
    "        support = item_count[item] / n_row\n",
    "        if support >= min_support:\n",
    "            freq_item.append(item)\n",
    "\n",
    "        item_support[item] = support\n",
    "\n",
    "    return freq_item, item_support\n",
    "\n",
    "\n",
    "def _apriori(transaction_list, min_support=0.01):\n",
    "    \"\"\"\n",
    "    pass in the transaction data and the minimum support threshold to obtain the frequent itemset. \n",
    "        Also store the support for each itemset, they will be used in the rule generation step\n",
    "    @param transaction_list: list of transactions with transaction items being coded by their sequential indexes\n",
    "    @type transaction_list: List[Set(int)]\n",
    "    @param min_support: Minumum support of the itemsets returned. \n",
    "        The support is frequency of which the items in the rule appear together in the data set.\n",
    "    @type min_support: Float between 0 and 1\n",
    "    @return:\n",
    "        freq_items: List of list k-itemset, k = 0, ..n\n",
    "        item_support_dict: Dict of itemset, size k = 0, ..n\n",
    "    @rtype:\n",
    "        freq_items: List[List]\n",
    "        item_support_dict: Dict, item: support, support is Float between 0 and 1\n",
    "    \"\"\"\n",
    "    # generate size-one-candidates (one-item sets) from the list of transactions\n",
    "    size_one_candidates = get_candidates(transaction_list)\n",
    "\n",
    "    # find candidates/item sets whose support >= min_support from size_one_candidates\n",
    "    freq_item, item_support_dict = create_freq_item(transaction_list, size_one_candidates, min_support=min_support)\n",
    "\n",
    "    # generate size-k candidates from the list of qualified qualified size-one item sets (aka freq_items)\n",
    "    freq_items = [freq_item]\n",
    "\n",
    "    # loop through freq_items and add list of k-incremental-size to it while looping\n",
    "    k = 0\n",
    "    while len(freq_items[k]) > 0:\n",
    "\n",
    "        # get list of size-k item sets\n",
    "        freq_item = freq_items[k]\n",
    "        \n",
    "        # generate k+2 itemset\n",
    "        size_k_candidates = generate_candidate_k(freq_item, k)\n",
    "\n",
    "        # find frequent item sets/candidates of k-size\n",
    "        freq_item, item_support = create_freq_item(transaction_list, size_k_candidates, min_support=min_support)\n",
    "\n",
    "        # append to the qualified frequent item set to freq_items and update their support\n",
    "        freq_items.append(freq_item)\n",
    "        item_support_dict.update(item_support)\n",
    "\n",
    "        # increment k and keep looping to add until exhausted\n",
    "        k += 1\n",
    "\n",
    "    return freq_items, item_support_dict\n",
    "\n",
    "\n",
    "def compute_conf(freq_items, item_support_dict, freq_set, subsets, min_confidence):\n",
    "    \"\"\"\n",
    "    Create the rules and returns the rules info and the rules's\n",
    "        right hand side (used for generating the next round of rules) \n",
    "        if it surpasses the minimum confidence threshold\n",
    "    @params:\n",
    "        freq_items: List of list k-itemset, k = 0, ..n\n",
    "        item_support_dict: Dict of itemset, size k = 0, ..n\n",
    "        freq_set: itemset\n",
    "        subsets: subset of freq_set\n",
    "        min_confidence: The minimum confidence of the rules returned. Given a rule X -> Y, the\n",
    "            confidence is the probability of Y, given X, i.e. P(Y|X) = conf(X -> Y)\n",
    "    @type:\n",
    "        freq_items: List[List]\n",
    "        item_support_dict: Dict, item: support, support is Float between 0 and 1\n",
    "        freq_set: List[frozenset]\n",
    "        subsets: frozenset\n",
    "        min_confidence: Float between 0 and 1\n",
    "    @return:\n",
    "        rules: List of rule, rule (Typle) include:\n",
    "            - lhs: left hand side\n",
    "            - rhs: right hand size\n",
    "            - conf: confidence score\n",
    "            - lift: lift score\n",
    "        right_hand_size: List of rhs\n",
    "    @rtype:\n",
    "        rules: List[Tuple]\n",
    "        right_hand_size: List[frozenset]\n",
    "    \"\"\"\n",
    "    # rule X->Y-X\n",
    "    # lhs = X\n",
    "    # rhs = Y-X\n",
    "    rules = []\n",
    "    right_hand_side = []\n",
    "\n",
    "    # create the left hand side of the rule\n",
    "    # and add the rules if it's greater than\n",
    "    # the confidence threshold\n",
    "    for rhs in subsets:\n",
    "        # create the left hand side of the rule\n",
    "        lhs = freq_set - rhs\n",
    "        # compute confidence of rule\n",
    "        conf = item_support_dict[freq_set] / item_support_dict[lhs]\n",
    "        # if conf >= min_confidence, add rule to List of rule\n",
    "        if conf >= min_confidence:\n",
    "            lift = conf / item_support_dict[rhs]\n",
    "            # defince rule and add into List of rule returned\n",
    "            rules_info = lhs, rhs, conf, lift\n",
    "            rules.append(rules_info)\n",
    "            right_hand_side.append(rhs)\n",
    "\n",
    "    return rules, right_hand_side\n",
    "\n",
    "\n",
    "def create_rules(freq_items, item_support_dict, min_confidence):\n",
    "    \"\"\"\n",
    "    Create the association rules,\n",
    "    rule contain rule, left hand side, right hand side, confidence, lift\n",
    "    @param:\n",
    "        freq_items: List of list k-itemset, k = 0, ..n\n",
    "        item_support_dict: Dict of itemset, size k = 0, ..n\n",
    "        min_confidene: Minimum of confidence score\n",
    "    @type:\n",
    "        freq_items: List[List]\n",
    "        item_support_dict: Dict, item: support, support is Float between 0 and 1\n",
    "        min_confidence: Float between 0 to 1\n",
    "    @return:\n",
    "        association_rules: List of rules\n",
    "    @rtype:\n",
    "        association_rules: List[tuple]\n",
    "    \"\"\"\n",
    "    association_rules = []\n",
    "\n",
    "    # for the list that stores the frequent items, loop through\n",
    "    # the second element to the one before the last to generate the rules\n",
    "    # because the last one will be an empty list. It's the stopping criteria\n",
    "    # for the frequent itemset generating process and the first one are all\n",
    "    # single element frequent itemset, which can't perform the set\n",
    "    # operation X -> Y - X\n",
    "    for idx, freq_item in enumerate(freq_items[1:(len(freq_items) - 1)]):\n",
    "        for freq_set in freq_item:\n",
    "            # start with creating rules for single item on\n",
    "            # the right hand side\n",
    "            subsets = [frozenset([item]) for item in freq_set]\n",
    "            rules, right_hand_side = compute_conf(\n",
    "                freq_items, item_support_dict, freq_set, subsets, min_confidence)\n",
    "            association_rules.extend(rules)\n",
    "\n",
    "            # starting from 3-itemset, loop through each length item\n",
    "            # to create the rules, as for the while loop condition,\n",
    "            # e.g. suppose you start with a 3-itemset {2, 3, 5} then the \n",
    "            # while loop condition will stop when the right hand side's\n",
    "            # item is of length 2, e.g. [ {2, 3}, {3, 5} ], since this\n",
    "            # will be merged into 3 itemset, making the left hand side\n",
    "            # null when computing the confidence\n",
    "            if idx != 0:\n",
    "                k = 0\n",
    "                while len(right_hand_side[0]) < len(freq_set) - 1:\n",
    "                    ck = generate_candidate_k(right_hand_side, k=k)\n",
    "                    rules, right_hand_side = compute_conf(freq_items, item_support_dict,\n",
    "                                                          freq_set, ck, min_confidence)\n",
    "                    association_rules.extend(rules)\n",
    "                    k += 1\n",
    "\n",
    "    return association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = parse(\"data/a1_market_basket_optimisation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-84fa4f0618f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransaction\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrozenset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msize_one_candidates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "size_one_candidates = []\n",
    "    # loop through each transaction to create  item sets of size-one (one-item sets)\n",
    "for transaction in trans:\n",
    "    for i in transaction:\n",
    "        print(i)\n",
    "        i = frozenset([i])\n",
    "        if i not in size_one_candidates:\n",
    "            size_one_candidates.append(i)\n",
    "size_one_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_trans = [len(items) for items in trans.values()]\n",
    "items_lst = set()\n",
    "    \n",
    "itemcount_track = list()    \n",
    "    \n",
    "for i in trans.values():\n",
    "    for j in i:\n",
    "        items_lst.add(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(items_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apyori import apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "associations = apriori(trans, min_length = 2, min_support = 0.2, min_confidence = 0.2, min_lift = 3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-495fa25ecec4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0massociations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massociations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/apyori.py\u001b[0m in \u001b[0;36mapriori\u001b[0;34m(transactions, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;31m# Calculate supports.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m     \u001b[0mtransaction_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransactionManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m     support_records = _gen_support_records(\n\u001b[1;32m    283\u001b[0m         transaction_manager, min_support, max_length=max_length)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/apyori.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(transactions)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransactionManager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtransactions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mTransactionManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/apyori.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, transactions)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtransaction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_transaction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransaction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_transaction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransaction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/apyori.py\u001b[0m in \u001b[0;36madd_transaction\u001b[0;34m(self, transaction)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mtransaction\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mA\u001b[0m \u001b[0mtransaction\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0man\u001b[0m \u001b[0miterable\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0meg\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'A'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'B'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \"\"\"\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransaction\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__transaction_index_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__items\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "associations = list(associations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([[1, 2], [3, 4], [5, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[35, 44],\n",
       "       [44, 56]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(arr.T, arr.T.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 3, 5],\n",
       "       [2, 4, 6]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [5, 6]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.unique(np.array([1, 0, 1, 2, 0, 1, 0, 1, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
